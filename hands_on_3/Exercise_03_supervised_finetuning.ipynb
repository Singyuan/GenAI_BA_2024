{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is a competition hosted on [Kaggle](https://www.kaggle.com/competitions/data-assistants-with-gemma) publish by Google.\n",
        "\n",
        "Supervised Fine-Tuning (SFT) adapts pre-trained models to specific tasks using labeled data, improving performance by adjusting the entire model. [LoRA](https://arxiv.org/abs/2106.09685) is an efficient fine-tuning approach within SFT that reduces computational and storage costs by introducing low-rank matrices."
      ],
      "metadata": {
        "id": "dnhh9dWILUbS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHe77asU56_L",
        "outputId": "f8f8c210-be32-4dd6-b6a5-94122dc07b1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.49.0)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.50.0-py3-none-any.whl.metadata (39 kB)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.0->bitsandbytes)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
            "Downloading transformers-4.50.0-py3-none-any.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m886.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, transformers, bitsandbytes\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.49.0\n",
            "    Uninstalling transformers-4.49.0:\n",
            "      Successfully uninstalled transformers-4.49.0\n",
            "Successfully installed bitsandbytes-0.45.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 transformers-4.50.0\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Collecting trl\n",
            "  Downloading trl-0.16.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: accelerate>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from trl) (1.5.2)\n",
            "Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from trl) (3.4.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl) (13.9.4)\n",
            "Requirement already satisfied: transformers>=4.46.0 in /usr/local/lib/python3.11/dist-packages (from trl) (4.50.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (0.29.3)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=3.0.0->trl)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (4.67.1)\n",
            "Collecting xxhash (from datasets>=3.0.0->trl)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=3.0.0->trl)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=3.0.0->trl)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (3.11.14)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl) (0.21.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (2.18.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.0.0->trl) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.0.0->trl) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.0.0->trl) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.0.0->trl) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.0.0->trl) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.0.0->trl) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=3.0.0->trl) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl) (4.12.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.34.0->trl) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate>=0.34.0->trl) (3.0.2)\n",
            "Downloading trl-0.16.0-py3-none-any.whl (335 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m335.7/335.7 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, trl\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 trl-0.16.0 xxhash-3.5.0\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.50.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.5.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.29.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (2024.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U transformers bitsandbytes accelerate\n",
        "!pip install datasets --no-deps\n",
        "!pip install trl\n",
        "!pip install peft"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213,
          "referenced_widgets": [
            "a638ece6bacf47b497aedc9848fa7d67",
            "c047f6c38ac44594b11168bcfd6f45d3",
            "35ec398d2b504e9d8133c65a3ef83d10",
            "09dead0b943d4e8fb60b07368cf80909",
            "ada194a187e6413a9fb28079596059c8",
            "e63303512a734e38adb048d1973547f2",
            "ed4066975cbf46f5abda8b630245aa0e",
            "8549941cc6e94ee19efca87abd8036bc",
            "398fb4f3993643128a9b9c2451b2c133",
            "85bd56c197d641ffaccbcaf62000b924",
            "68568aea5f29432fb58d223c6e3e4678",
            "4b2453dd95794798be0a7f3091c73a77",
            "0227910681574ce493a71973f8b61695",
            "d6eecb2ef653484492862f079ccd6398",
            "c6dc7c74ca6442d3b18dee1e4517ffa9",
            "65fbace232c94d2b838be43345753294",
            "10531506512c449db420751f62a0fb01",
            "d136b929790d470fb8d12410bdd71a0e",
            "fb8833fb22a44bb4884b2225b4945e38",
            "4575ce954f544bfb8dbec3ea086213ef",
            "c16418c72b7a4d1bbb10bfb44d8aa4b1",
            "a7c9cc32e7bc427188047cac796bc097",
            "e3d5019bea254d8092d81dfd16d4109c",
            "312bad709c4740ac912d0117e7e2d2f7",
            "8bf013c903ac4a1d8d2c1c44b0404e05",
            "b1b8458cf996490d925ce2bfe0db7fcd",
            "b6af943662f44ceabe6b2b1701637239",
            "e97c36cd98ae4d96b727d2c38120ea98",
            "613e53eeb55e448d8fe28b1f2f2dbcf2",
            "adba5bdbb6584001a8a0edd6f618f522",
            "5520bb236f0c45699a62cb9f82686478",
            "32f27b805b504e61b517fbce8759dd61",
            "f35a86b676eb48059db384dbfd6c4c78",
            "f900ca1c5d7f49feb0e2f9e62444db7e",
            "b6e4a36893b744fda0b897d666c3cff0"
          ]
        },
        "id": "1HjAgsfQ8eKR",
        "outputId": "e99e2427-10f3-4c92-9dae-2f97a1c9d3e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a638ece6bacf47b497aedc9848fa7d67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token has not been saved to git credential helper.\n",
            "WARNING:huggingface_hub._login:Token has not been saved to git credential helper.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoProcessor\n",
        "import torch\n",
        "from IPython.display import Markdown\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from peft import LoraConfig\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "import ast"
      ],
      "metadata": {
        "id": "k87ce8Ca8es7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Model\n",
        "We use Google's model [Gemma 1.0](https://huggingface.co/google/gemma-2b-it) 2B instruct version."
      ],
      "metadata": {
        "id": "aOPQN2mkJ1x5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_id = 'google/gemma-2b'\n",
        "model_id = 'google/gemma-2b-it'\n",
        "\n",
        "# 4 Bit Config\n",
        "bnb_config_4bit = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config_4bit, low_cpu_mem_usage=True, trust_remote_code=True)\n",
        "\n",
        "# Loading Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "tokenizer.padding_side = \"right\"\n",
        "print(f\"Gemma 1.0 4Bit Model size: {model.get_memory_footprint()/1024./1024./1024.:,} GB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387,
          "referenced_widgets": [
            "0349fc4b516246d3bc16fa19c430c347",
            "5b3b0541f5c24a699d1ed49316187452",
            "a0418157363c47a78ad23c04c6169fab",
            "f974e368e2b048348e68ef81145fbda0",
            "a5694554abf840a58e07527c1c20f530",
            "5bef6972aea54e7c952125b2eaebaec5",
            "3f6b06c80b20487284d0d997aed057cb",
            "a24bfafa09a94115ad7ce34761ad544b",
            "fdbd091551344fd2a4fd36033c19ff89",
            "a536810030184a72bbea86863c7bda22",
            "2aa375b3a1a449648cdf5fd77e53c900",
            "fbd27d69957c419cbbc712ee43234597",
            "7bcdd27b9fab44e0836e6ae5cd647648",
            "154b2652a2d04969895d7f533217024a",
            "1482d9c1b86048d685ff5740eda8e628",
            "426d408d0ab242c0a9843825238735e6",
            "79596c8dd4594975996ef7490d17346a",
            "945b75aa2f644c6fa6f4d7530c0d214f",
            "6c7449d20e8141f2a4e9b48a6492d087",
            "2ab106e608ee4e5382d41b774b26b427",
            "26117171583f43478838414a9247b50d",
            "9741ece516b24c18af97627497a51c3b",
            "9e121d9a9d4d4d79a2847babe81640aa",
            "107c26ec415d4692b9e805fc26848ccd",
            "cb784f54a9664773896944da97edde15",
            "9772d06f2ee5401aab229d080a0b8f11",
            "ea79c3fac82c42e184b50d140d03ce20",
            "f7c1252b6151447d888d8206c1333f62",
            "4b710fbd84d6424f96685c4514c6d368",
            "d52a11a67b6c45988563b6d07239eb3e",
            "b37e2ce0f4b944bdb58c518391a9c2b4",
            "949541412ea44641ae5d329a3f6ebd8b",
            "5aeb0621e6cf46509db791a38a1aa998",
            "518d9b8d5fba492a8dd74746b7414595",
            "89b5ad8364db4f9897f2ffb314a230d8",
            "9b7799255caf4f97acc09708bbc8c766",
            "3e2348fb434d49d584434b1e32313d96",
            "9f86512f08b44325b8bba869e16f03cb",
            "667fcbcc7dd3456f8afb55a5cab9fd86",
            "e02a91df6cc147ada9c8029a67242c53",
            "abdca5f7865045b0812e6547c4b93945",
            "d93fea27dd90471fa30f8bcf6b55baa8",
            "2328ebc00eb24aad9908eb1710f48a99",
            "8b16b20c82c0400da7eb407df2054b2a",
            "69ff7e8456cb44bfb95202b018ebfcfd",
            "133990555185428aa7333ed923298c66",
            "cea4d7eb5b01448eb7147d84b2c9eca2",
            "dc70386cb4c84e8f8ccaeee8c21dfde9",
            "9c6865eff88941c4a5b2d6e235a353f6",
            "a68d7f3aa34e4f07b26eed74832da336",
            "cecc1e1c48174d7ea0801e0592a4a4f9",
            "ff2b736abcfe4570b5a6e0c072ef56d2",
            "71edd640fb3f4b858f33bf900a06ddee",
            "eb9d2e39ff5141bdb6d4f7db4e22017f",
            "42ede22cc4f249db8c78256467a5a985",
            "b75e5b9590d349f1a43ca31dd873d523",
            "580ce6610cb6487abcc069c349252830",
            "1d973695b6ea4cd6911c3a91290f271f",
            "d9793e99951e477e8ddf9af3a8be7dea",
            "564789bbc1004ad59522e388563b09d0",
            "8f3cc0778dd941ef8c7a62b8908781fc",
            "03d05b6d8a934108ae041d2220d2ef75",
            "e7bf4bbbfb674e65a85adb0881f1f940",
            "c09b1501628b4651a34254d61411694c",
            "c9291dc31bb24095abf11a997681bff9",
            "8119bca56eb24fb1b8c367dcd0023ecf",
            "6c3ed39d29d546a8ad784d0234e086e2",
            "ccb2a92ad0094c7cb3bc01557c13fa0e",
            "d8ff801fe91844448c9b37f3b4b313d8",
            "d326828b787b44ccbb125f5c6f89969b",
            "b2e0b092a3534e90ab9d6420a650ae11",
            "e652887837ba444ca1b5f344a637d1ba",
            "efc09e92ffad4dc19c6993f5a6195119",
            "8f59321061ca43be9d39bf3d4033df70",
            "9b94e92c213141a38fffebcb92546320",
            "2a2e75b345c8429d878bc9c70c7ff233",
            "2d2b2cd2698a4c828a2ff37191dc57a4",
            "4a47223a50454381a090bb334e93ab6c",
            "47e41361d33c4c3887cbad709851d609",
            "df343defb3d74d2d968195d239cad06c",
            "a41d7e67d52e44dfaa1c382ee684519a",
            "54a19f7c8b724404992c28ac48f5e469",
            "d0ba86b4e4db47e185c950c0e0888f8f",
            "02ec2cf52e05472fb3e89f500d6c4979",
            "f45f1f8409904043b7737f6061eb2875",
            "91981840d2c04453a5bef7a4d268130a",
            "4dd6dad25b4647a38f191b362fc8083b",
            "7c78add1224a4b40b9e312819002c1c2",
            "400b991b3e624db79f2fd7cfe2af2e69",
            "c5db5b158c884078bfe204f752a2967d",
            "6d5c121c018d4fcba03e60fae8d47a51",
            "a04991c6246f471691f37fd759dfb576",
            "7947a6dc9ac54815b3169ca6e2f390c6",
            "56aa11cc8ff3406ea62baf733f6b4e10",
            "05ee198117664b0e8af76ec7453d0b54",
            "144c6afbae6041f1b49465875e9919f1",
            "fffd3c3ce47d40199f2ce62679ace175",
            "2140d29c66d64cb5ad027d6f18b11bd4",
            "8ff9621fc7f6491f8fb1065aeb315626",
            "401a12bdb97f45f58f07d2511a87cb11",
            "57edf341372e4f27a3dc9ed8562aac94",
            "7d0143397e334eb0ad813037c61b59a1",
            "cf5d00a4cc2a41038d8d7fb71a83ca78",
            "57ad739058164b2b9467369aa758fa95",
            "47c8393c99d045e89441c003d2cc7b82",
            "7afcc27109d74264b46459f31004d281",
            "0c0803136e064085b6e53769e41cca24",
            "3cfe22f75f7b4dab9be6afd76d181080",
            "61b7ad9ecae54f8d8efddb5a3dfbdc51",
            "8c932a59e89249be9be946419e59ab29",
            "14022f81bebc45ea8a7dd5c8c9a764dd",
            "bec3dbf9e76841b980ea6f660a963ded",
            "f00de49eb8e549d6884e5a9f2d20e78d",
            "7f17753eef9947999dbe169859bcb0b7",
            "ea751cab195a4f439b81e07e9ea0e4e7",
            "ace42a1517a147e898bbcfab73ecccfa",
            "5bbd523db7a4467da9ed6174b07fb91e",
            "d39ddf266f17403b8177b0e4455baa77",
            "7cf65a740f524c319fa2ffb70d71426d",
            "54bca78c02fd4af48e7fe5aca124cada",
            "734faf70bcc1443baf6be009e38a9971"
          ]
        },
        "id": "Werg88wk8gMz",
        "outputId": "be5585b7-eeeb-4975-9019-4e30892a6fc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/627 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0349fc4b516246d3bc16fa19c430c347"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/13.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fbd27d69957c419cbbc712ee43234597"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e121d9a9d4d4d79a2847babe81640aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "518d9b8d5fba492a8dd74746b7414595"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/67.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69ff7e8456cb44bfb95202b018ebfcfd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b75e5b9590d349f1a43ca31dd873d523"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c3ed39d29d546a8ad784d0234e086e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/34.2k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a47223a50454381a090bb334e93ab6c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "400b991b3e624db79f2fd7cfe2af2e69"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "401a12bdb97f45f58f07d2511a87cb11"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14022f81bebc45ea8a7dd5c8c9a764dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemma 1.0 4Bit Model size: 1.8995556831359863 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system =  \"You are a skilled software engineer. \"\n",
        "question =system + \"What is the difference between a variable and an object\"\n",
        "\n",
        "prompt = f\"Question: {question} \\n Answer: \"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True, max_length=512).to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, num_return_sequences=1, max_new_tokens=512)\n",
        "\n",
        "text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# print(text)\n",
        "Markdown(text.split(\"Answer:\")[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "id": "TffI6Jkt95Xy",
        "outputId": "2e6c0f6f-b4a2-4c75-c4d7-bfa593a677c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " \n\nSure, here's the difference between a variable and an object in software engineering:\n\n**Variable:**\n\n* A variable is a named memory location that stores a single piece of data.\n* It is declared using a keyword (e.g., int, float, string).\n* The variable name should follow the same rules as other identifiers (e.g., cannot start with a number).\n* Variables are used to store and retrieve data in a program.\n* A variable can be assigned a value once or multiple times.\n\n**Object:**\n\n* An object is a more complex data structure that contains multiple variables and methods.\n* It is created using a constructor function.\n* Objects are stored in memory and have their own memory addresses.\n* Objects can contain multiple variables of different data types.\n* Objects can have methods that perform operations on their data.\n* Objects are used to represent real-world entities or data structures.\n\n**Here's an example to illustrate the difference:**\n\n```python\n# Variable\nname = \"John\"\nage = 30\n\n# Object\nperson = {\"name\": \"John\", \"age\": 30}\n```\n\nIn this example, the `name` variable is a variable that stores a string, while the `person` object is an object that contains multiple variables and methods.\n\n**Key differences:**\n\n| Feature | Variable | Object |\n|---|---|---|\n| Data type | Any | Objects |\n| Memory address | No | Yes |\n| Creation | Using `var` keyword | Using constructor function |\n| Scope | Local to function | Global |\n| Use case | Storing and retrieving data | Representing real-world entities |"
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Supplementary Dataset"
      ],
      "metadata": {
        "id": "Q3tg6HdGKMBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown '1HKzCy_vxb8hUzVEWhhgL_pNTIXIvEdw7' --output Dataset_Python_Question_Answer.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHbBMi8ob6OL",
        "outputId": "fe34c07c-ebf3-4096-b1c6-890472c08ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HKzCy_vxb8hUzVEWhhgL_pNTIXIvEdw7\n",
            "To: /content/Dataset_Python_Question_Answer.csv\n",
            "\r  0% 0.00/721k [00:00<?, ?B/s]\r100% 721k/721k [00:00<00:00, 73.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('Dataset_Python_Question_Answer.csv')\n",
        "dataset = Dataset.from_pandas(data)\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-p7C8CwNayV7",
        "outputId": "3e66ccc5-9380-44d8-8db3-8d0f3f2fe577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Question  \\\n",
              "0   What is the difference between a variable and...   \n",
              "1   What is the difference between a built-in fun...   \n",
              "2   What is the difference between the `print` fu...   \n",
              "3   What is the difference between an expression ...   \n",
              "4   What is the difference between `True` and `Fa...   \n",
              "\n",
              "                                              Answer  \n",
              "0  [\"Sure, here's the difference between a variab...  \n",
              "1  [\"Sure. Here's the difference between built-in...  \n",
              "2  [\"Sure. Here's the difference between the two ...  \n",
              "3  [\"Sure! Here's the difference between an expre...  \n",
              "4  [\"Sure. Here's the difference between `True` a...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32b62d00-5027-4df2-ad97-175b330b4abc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the difference between a variable and...</td>\n",
              "      <td>[\"Sure, here's the difference between a variab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What is the difference between a built-in fun...</td>\n",
              "      <td>[\"Sure. Here's the difference between built-in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the difference between the `print` fu...</td>\n",
              "      <td>[\"Sure. Here's the difference between the two ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What is the difference between an expression ...</td>\n",
              "      <td>[\"Sure! Here's the difference between an expre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the difference between `True` and `Fa...</td>\n",
              "      <td>[\"Sure. Here's the difference between `True` a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32b62d00-5027-4df2-ad97-175b330b4abc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-32b62d00-5027-4df2-ad97-175b330b4abc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-32b62d00-5027-4df2-ad97-175b330b4abc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-78f5edfc-50a8-478a-8e5f-5bcb09e2b68f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-78f5edfc-50a8-478a-8e5f-5bcb09e2b68f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-78f5edfc-50a8-478a-8e5f-5bcb09e2b68f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 419,\n  \"fields\": [\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 419,\n        \"samples\": [\n          \" What is recursion with a default case in Python? Give an example.**\",\n          \" What is the difference between a dictionary and a list in terms of performance? \",\n          \" What are functions in Python? Explain how you can use functions to reuse code?**\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 419,\n        \"samples\": [\n          \"[\\\"Sure. Here's an example of recursion with a default case in Python:\\\", '```python', 'def factorial(n):', '  \\\"\\\"\\\"', '  This function computes the factorial of a non-negative integer n.', '  If n is 0, the factorial is defined to be 1.', '  \\\"\\\"\\\"', '  if n == 0:', '    return 1', '  else:', '    return n * factorial(n-1)', 'print(factorial(5))', '```', '**Explanation:**', '1. The `factorial()` function takes a single argument, `n`, which represents the non-negative integer for which the factorial is calculated.', '2. It has a base case if `n` is equal to 0: If `n` is 0, the factorial of 0 is defined to be 1. This is a recursive base case that stops the recursion when `n` reaches 0.', '3. For values of `n` greater than 0, the function recursively calls itself with the argument `n-1` and multiplies the result by `n`. This recursive step computes the factorial of `n`.', '4. If no other base cases apply, the function returns the result of the recursive call with the argument `n-1`. This is the recursive case of the recursion.', '5. Finally, the `factorial()` function is called with the argument 5, which triggers the recursion process. The result of this recursive call is printed to the console.', 'The output of this code will be 120, which is the factorial of 5.']\",\n          \"[\\\"Sure. Here's the difference between a dictionary and a list in terms of performance:\\\", '**Dictionaries:**', '* Accessing a key in a dictionary is faster on average than accessing a key in a list.', '* Dictionaries have a logarithmic time complexity, meaning that the search operation will take O(log n) time, where n is the number of items in the dictionary.', '* This is because dictionaries use a hash table data structure, which allows for efficient key-based access.', '**Lists:**', '* Accessing a key in a list takes O(n) time, on average.', '* Lists are implemented using an array data structure, which can be slow to search for elements.', '* However, lists have other advantages, such as dynamic resizing and the ability to perform element insertions and deletions.', '**Additional Differences:**', '* **Memory usage:** Dictionaries use more memory than lists, as they need to store the key-value pairs in memory.', '* **Performance on small lists:** For small lists, the performance difference between dictionaries and lists is negligible. However, as the list size increases, the difference becomes more pronounced.', '* **Use cases:** Dictionaries are typically used when speed and efficiency are critical, such as in data structures, dictionaries are commonly used for key-based lookups and insertions, while lists are used for more general purpose data management.', 'In summary, dictionaries offer significantly faster access times for specific operations compared to lists due to their hash table implementation but at the cost of larger memory usage and slower access for non-key elements.']\",\n          \"['**Functions in Python are reusable blocks of code that perform specific tasks.**', 'They allow you to define a set of instructions once and then call them repeatedly with different input values without the need to rewrite the code from scratch.', \\\"Here's how to use functions in Python:\\\", '**1. Define Function:**', '```python', 'def function_name(argument1, argument2):', '    # function body', '    return result', '```', '**2. Call Function:**', '```python', 'result = function_name(input_value1, input_value2)', '```', '**3. Pass Arguments:**', 'Functions can accept multiple arguments of different types, separated by commas. The function executes the code within the function body for each argument.', '**4. Return a Value:**', '```python', 'def function_name(argument1, argument2):', '    return calculation(argument1, argument2)', '```', '**5. Example:**', '```python', 'def square(x):', '    return x * x', '# Call the function with different arguments', 'result = square(5)', 'print(result)  # Output: 25', '```', '**Benefits of using functions:**', '* **Reusability:** You can reuse the code in different parts of your program.', '* **Efficiency:** It eliminates the need to repeatedly write the same code.', '* **Maintainability:** Functions make the code easier to understand and modify.', '* **Code organization:**Functions help you organize your code logically.', '**Additional Notes:**', '* Functions can also be nested to create complex logic.', '* Functions can be made accessible to other modules by importing them.', '* You can use functions in other programming languages like C++ and PHP as well.']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('The size of the dataset: ', data.shape, '\\b.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRv2KJRSjBLB",
        "outputId": "49f3599e-1a4e-4b31-ae9e-a3a69ca0a6d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The size of the dataset:  (419, 2) \b.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Supervised Finetune the model with LoRA (Low-Rank Adaptation)\n",
        "**Supervised Fine-Tuning (SFT)** is a method for adapting pre-trained models to **specific tasks** using labeled data. It involves adjusting the entire model to improve performance on a given task.\n",
        "\n",
        "- **LoRA (Low-Rank Adaptation)**: A specialized approach within SFT that focuses on efficient fine-tuning by introducing low-rank matrices. It allows for fewer parameter updates and reduces computational and storage costs. Please refer to [Paper](https://arxiv.org/abs/2106.09685) for more details. There is a brief survey [Website](https://towardsdatascience.com/understanding-lora-low-rank-adaptation-for-finetuning-large-models-936bce1a07c6/)."
      ],
      "metadata": {
        "id": "KHsQtXTFKdB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def formatting_func(example):\n",
        "    template = \"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\"\n",
        "    list_from_str = ast.literal_eval(example['Answer'])\n",
        "    line = template.format(instruction=example['Question'], response='\\n '.join(list_from_str))\n",
        "    return line\n"
      ],
      "metadata": {
        "id": "d2nOsh01fTmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LoRA Arguments\n",
        "- **r (int)**: Defines the rank of the low-rank decomposition in LoRA, balancing memory usage and accuracy, with a default value of 8.\n",
        "- **target_modules (List[str])**: Specifies the Transformer layers where LoRA will be applied, including `q_proj`, `o_proj`, `k_proj`, `v_proj`, `gate_proj`, `up_proj`, and `down_proj`.\n",
        "- **task_type (str, optional)**: Specifies the fine-tuning task type, though not used in this configuration, it can help optimize LoRA for specific tasks like \"CAUSAL_LM\".\n",
        "\n",
        "Please see [LoRA Document](https://huggingface.co/docs/peft/package_reference/lora) for more details."
      ],
      "metadata": {
        "id": "jn43ex4JMN1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK6cL01xkKhu",
        "outputId": "5ef331a2-9252-46b0-a275-f66605fc8c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GemmaForCausalLM(\n",
            "  (model): GemmaModel(\n",
            "    (embed_tokens): Embedding(256000, 2048, padding_idx=0)\n",
            "    (layers): ModuleList(\n",
            "      (0-17): 18 x GemmaDecoderLayer(\n",
            "        (self_attn): GemmaAttention(\n",
            "          (q_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
            "          (k_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
            "          (v_proj): Linear4bit(in_features=2048, out_features=256, bias=False)\n",
            "          (o_proj): Linear4bit(in_features=2048, out_features=2048, bias=False)\n",
            "        )\n",
            "        (mlp): GemmaMLP(\n",
            "          (gate_proj): Linear4bit(in_features=2048, out_features=16384, bias=False)\n",
            "          (up_proj): Linear4bit(in_features=2048, out_features=16384, bias=False)\n",
            "          (down_proj): Linear4bit(in_features=16384, out_features=2048, bias=False)\n",
            "          (act_fn): GELUActivation()\n",
            "        )\n",
            "        (input_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
            "        (post_attention_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
            "      )\n",
            "    )\n",
            "    (norm): GemmaRMSNorm((2048,), eps=1e-06)\n",
            "    (rotary_emb): GemmaRotaryEmbedding()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=2048, out_features=256000, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://stackoverflow.com/questions/76768226/target-modules-for-applying-peft-lora-on-different-models\n",
        "def get_specific_layer_names(model):\n",
        "    # Create a list to store the layer names\n",
        "    layer_names = []\n",
        "\n",
        "    # Recursively visit all modules and submodules\n",
        "    for name, module in model.named_modules():\n",
        "        # Check if the module is an instance of the specified layers\n",
        "        if isinstance(module, (torch.nn.Linear, torch.nn.Embedding, torch.nn.Conv2d)):\n",
        "            # model name parsing\n",
        "\n",
        "            layer_names.append('.'.join(name.split('.')[4:]).split('.')[0])\n",
        "\n",
        "    return layer_names\n",
        "\n",
        "list(set(get_specific_layer_names(model)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNKpkT4jke5o",
        "outputId": "3d64f5ea-9989-49a1-b720-7029e7e139f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " 'up_proj',\n",
              " 'down_proj',\n",
              " 'v_proj',\n",
              " 'k_proj',\n",
              " 'o_proj',\n",
              " 'gate_proj',\n",
              " 'q_proj']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lora_config = LoraConfig(\n",
        "    r = 8,\n",
        "    target_modules = [\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    task_type = \"CAUSAL_LM\",\n",
        ")"
      ],
      "metadata": {
        "id": "RPcqi33Nfbv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SFTConfig Arguments\n",
        "- **per_device_train_batch_size (int)**: Specifies the batch size for each device (GPU). In this case, it's set to 1 for low memory usage.\n",
        "- **gradient_accumulation_steps (int)**: The number of steps to accumulate gradients before performing a backward pass. Here, gradients are accumulated over 4 steps.\n",
        "- **warmup_steps (int)**: The number of steps for learning rate warm-up before it reaches the specified `learning_rate`. This helps stabilize training in the beginning.\n",
        "- **max_steps (int)**: The total number of training steps to run. In this case, the training will stop after 50 steps.\n",
        "- **learning_rate (float)**: The learning rate for training. Here it's set to `2e-4`, which is a moderate value to prevent overshooting during optimization.\n",
        "- **fp16 (bool)**: Whether to use 16-bit precision for training (faster computation and less memory usage), set to `True` here.\n",
        "- **optim (str)**: The optimizer used for training. Here, `paged_adamw_8bit` is used for efficient training with 8-bit precision.\n",
        "- **max_seq_length (int)**: The maximum sequence length for inputs. Set to 512 tokens in this case to fit the model's requirements.\n",
        "\n",
        "Please see [SFTConfig Document](https://huggingface.co/docs/trl/v0.16.0/en/sft_trainer#trl.SFTConfig) for more details."
      ],
      "metadata": {
        "id": "OtncISGKNBy2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = SFTConfig(\n",
        "        per_device_train_batch_size=1,\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_steps=2,\n",
        "        max_steps=50,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=True,\n",
        "        logging_steps=1,\n",
        "        output_dir=\"outputs\",\n",
        "        optim=\"paged_adamw_8bit\",\n",
        "        max_seq_length=512,\n",
        "        report_to=\"tensorboard\",\n",
        "    )"
      ],
      "metadata": {
        "id": "MXwGGHRzfokR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset,\n",
        "    processing_class=tokenizer,\n",
        "    args=training_args,\n",
        "    peft_config=lora_config,\n",
        "    formatting_func=formatting_func,\n",
        "    # data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False, return_tensors=\"pt\"),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215,
          "referenced_widgets": [
            "f9e2e1662aa7462bb88bf2e2e5f93843",
            "2cf51565a8514a24af06777813f91336",
            "08694d7b99474f3998d5b981c48d0bc4",
            "89b6e2fb9a414b12a4b69f8765049f4f",
            "4105f31b4d1a4315b6e0077908f7aa3d",
            "d65d3dfad094415e904ae93cef0e9b54",
            "bd7dd5b536e24ebbbcc008c500eb3b0d",
            "aee9d1da4bb74d55ba8e3d87d926bf32",
            "24a1d6cc3b7c406d8a14dd12d44a94cf",
            "7bdd842a2592411c9071b7b48fd29c35",
            "07853ddcfcc2481eb76035e1fc4518e1",
            "e3be9de49ea64b96ae2604ff627e3b9f",
            "5c934acc8aff46c786cd8f3566a80b7b",
            "3615dc11abda4ae5b132954757c059ef",
            "3bd60856a2554b4aadbabaedfec684fe",
            "3e0db29ab18847bfba6f6fc684e31d28",
            "62d151258be24883aa131b0ce633763c",
            "d72803d3e17246229450b8e57ccbf834",
            "1d17587c7c8047318fdae00f30ea533b",
            "0819e0c9f59243ffb008f329176c1efc",
            "1b4309f5e96a4693a04c79a2c4077466",
            "593d4b6c0354425c81b201efb118e168",
            "489c973dc70540c3b8ab8820a475b5a6",
            "9b14149d4e284aed859ffff3512619ad",
            "771cc17a7b444e2b85a6c1e25daaf4dd",
            "92085288ce6e4b32848dd839cc0d91b1",
            "fe132d5667fd4a78864634e3f81ff6ad",
            "d5b4bb5e5f1b4d0485026def5ff0a17d",
            "93d3f99c1c0347d6aeafac1cc3ae657d",
            "ba60a8f0e3b64681a151c92639fcff8a",
            "783bc129653040329be61e58e99257ad",
            "85018c607f9245afa61d30398cec5126",
            "077f2e6ecbdf4800b022455b66b3808a",
            "c11279b4caa74cc6a8f62269af6934fe",
            "66f281dddcb74b78a586529d58a65a30",
            "3f4cea39d9c74123932e590de150a33e",
            "682facb621d440169e29094c70279a60",
            "c9181e406c9d417fb945c46a1b4dd981",
            "3f018de75eec4463b5e0341a453b532a",
            "4553fdee113044e1b2d5627a1f4cfb8a",
            "51119a9377e24616992c59c2d1068358",
            "5997a972a5cf4487897030a1a20205a4",
            "b2443c9d8ca140f99e6ec550b8ddea7d",
            "4c8b6fcf1a8e4b6bb5d25a4ad30ca84a",
            "940063ada3534dd9aeebf5ebf680295a",
            "f506a7a57e2646908c08f65080cd2387",
            "bc1869f83e494a05964deae374281963",
            "f5ec61d3fc45455ebe910c6d22fa796d",
            "2667fc0cfba64a81816bae0ae0bfa484",
            "b56dcabc670c401f8f9e3dbf54c86d35",
            "62b29167b37147f89208ae72434b3044",
            "b6a6ec69ae804a87b18c917104b295ed",
            "ba0d608bda0f4fd5bcf7814828f7914c",
            "905121fb4331427aa2a0da43ec6253e2",
            "cde2a535ab5e4737a9cfc35e664117d7"
          ]
        },
        "id": "f1NPIUUZffVK",
        "outputId": "4ee99f62-c55d-4293-828e-a2e639b120d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Applying formatting function to train dataset:   0%|          | 0/419 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9e2e1662aa7462bb88bf2e2e5f93843"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Converting train dataset to ChatML:   0%|          | 0/419 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3be9de49ea64b96ae2604ff627e3b9f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Applying chat template to train dataset:   0%|          | 0/419 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "489c973dc70540c3b8ab8820a475b5a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing train dataset:   0%|          | 0/419 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c11279b4caa74cc6a8f62269af6934fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Truncating train dataset:   0%|          | 0/419 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "940063ada3534dd9aeebf5ebf680295a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ],
      "metadata": {
        "id": "4Qfmf7zPlLhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ORAhjrsElCuL",
        "outputId": "c073925e-044d-414b-965b-bae299f9a6fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 01:51, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.943000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.933600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.846700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.778300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.790100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.841200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.727200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.719300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.808800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.615700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.624400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.467200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.629700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.551400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.600900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.581400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.457800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.588700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.547800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.553900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.507600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.592700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.644600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.522600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.494300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.487900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.510900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.454500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.438800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.430100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.515800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.548600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.509200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.549200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.412600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.495500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.481600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.564700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.553100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.408400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.483800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.428800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.408600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.416800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.483100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.390900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.473100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.513200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.349900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.548600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=50, training_loss=0.5645383900403976, metrics={'train_runtime': 114.3031, 'train_samples_per_second': 1.75, 'train_steps_per_second': 0.437, 'total_flos': 935863376732160.0, 'train_loss': 0.5645383900403976})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system =  \"You are a skilled software engineer. \"\n",
        "question =system + \"What is the difference between a variable and an object\"\n",
        "\n",
        "prompt = f\"Question: {question} \\n Answer: \"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True, max_length=512).to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(**inputs, num_return_sequences=1, max_new_tokens=512)\n",
        "\n",
        "text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# print(text)\n",
        "Markdown(text.split(\"Answer:\")[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "BbaazBzT4ffL",
        "outputId": "a8e54575-c666-4416-bfc9-7c617f2cf31f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " \nSure. Here's the difference between a variable and an object:\n **Variable:**\n * A variable is a named memory location that stores a single value.\n * It is a placeholder for a specific value, which can be changed later.\n * Variables are used to store data that is used in multiple parts of a program.\n * They are declared using the `=` operator, followed by the variable name and an assignment operator.\n * Example: `name = \"John\"`\n **Object:**\n * An object is a more complex data structure that contains multiple variables and methods.\n * It is an instance of a class, which defines the structure and behavior of the object.\n * Objects are created using the `new` keyword, followed by the class name and the constructor function.\n * Objects can have their own data and methods, which are not defined in the class.\n * They are used to represent real-world entities, such as people, animals, or data.\n * Example:\n ```python\n class Person:\n     name = \"\"\n     age = 0\n     def __init__(self, name, age):\n         self.name = name\n         self.age = age\n ```\n In summary, variables are used to store single values, while objects are used to represent complex data structures with multiple variables and methods."
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "- Paul Mooney and Ashley Chow. Google – AI Assistants for Data Tasks with Gemma. https://kaggle.com/competitions/data-assistants-with-gemma, 2024. Kaggle.\n",
        "- https://www.kaggle.com/code/shiivvvaam/pygemma-finetuned-rag/notebook\n",
        "- https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/fine-tune-llms-in-2024-with-trl.ipynb\n",
        "- https://clay-atlas.com/blog/2024/01/03/supervised-fine-tuning-sft-trainer/\n",
        "- https://ai.google.dev/gemma/docs/core/huggingface_vision_finetune_qlora?hl=zh-TW"
      ],
      "metadata": {
        "id": "jGnr09EqOEeP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tv2ZegzIoHDu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}